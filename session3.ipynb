{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------\n",
    "<a id='top'></a>\n",
    "## Session contents\n",
    "### [7. Map, ApplyMap, and Apply](#applying)\n",
    "### [8. Groupby](#aggregating)\n",
    "### [9. Merge/Join](#merging)\n",
    "### [Exercise set 3](#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "<a id='applying'></a>\n",
    "## 7. Map, ApplyMap, and Apply\n",
    "\n",
    "We've seen that pandas objects come with simple aggregation methods, and that numpy functions allow numerical operations on pandas objects. You might wonder whether we can use functions from other packages, or apply our own user-defined functions, in a similar way.\n",
    "\n",
    "Pandas provides this functionality through the following methods:\n",
    "\n",
    "    srs.map(f) - apply a function f element-wise to a Series (or DataFrame column)\n",
    "    df.applymap(f) - apply a function f element-wise to the entire DataFrame (i.e. the DataFrame equivalent of .map)\n",
    "    df.apply(f, axis) - apply a function f along columns (axis=0) or rows (axis=1) of a DataFrame\n",
    "    \n",
    "<img src=\"https://i.stack.imgur.com/DL0iQ.jpg\" title=\"Apply\" />\n",
    "\n",
    "Many of the functions we covered in the previous sessions are shorthand for these more general methods:\n",
    "\n",
    "    np.log(df['A']) --> df['A'].map(np.log)\n",
    "    df * 2 --> df.applymap(lambda x: x*2)\n",
    "    df.sum(axis=1) --> df.apply(sum, axis=1)\n",
    "    \n",
    "Generally, you should use map, apply, and applymap only if there is no Series or DataFrame method available. In this way, your code will be more readable and use any optimisations that pandas may have for these methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<span style=\"color:green\">Additional resources</span>\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.apply.html\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.applymap.html#pandas.DataFrame.applymap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first load up a test DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=list('ABCD'), data=np.random.randn(4, 4)*10)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ApplyMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is probably the simplest of the apply functions to understand. Let's convert every number in df to an int (dropping the decimal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.applymap(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create our own functions to apply to the DataFrame as well. Simple one-line functions can be declared using lambda functions. \n",
    "\n",
    "See http://www.secnetix.de/olli/Python/lambda_functions.hawk\n",
    "\n",
    "In the example below, we have formatted each element of the DataFrame as a percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.applymap(lambda x: str(x)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More complex functions can be applied by defining a function in the usual way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_or_three_plus_one(x):\n",
    "    \"\"\"Halve if even, triple and add one if odd\"\"\"\n",
    "    if x==1:\n",
    "        y = 1\n",
    "    elif np.mod(x, 2)==0:\n",
    "        y = x / 2\n",
    "    else:\n",
    "        y = 3*x + 1\n",
    "    return int(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.abs().applymap(int).applymap(half_or_three_plus_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method provides the same functionality as applymap, but for Series objects. Try some of the same functions above but on a single column or row of the DataFrame only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The apply method is a little more difficult to understand. It applies a particular function, often an aggregation, to each row or column independently. We've encountered a few examples of an apply-like method already, e.g., the df.sum() method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we call .apply and use the sum function with axis=0, we will be summing up the rows (or, summing \"along the columns\") of our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(sum, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sum along rows, simply pass axis=1 instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(sum, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using .apply, the argument to your function is the row or column itself (which is of course a Series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda x: x['C'], axis=1) # x is each row of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda x: x.iloc[-1], axis=0)  # x is each column of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_largest(srs):\n",
    "    srs = srs.copy()  # to make a local copy of the input\n",
    "    srs = srs.abs()\n",
    "    srs = srs.sort_values(ascending=True)\n",
    "    return srs.iloc[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(second_largest, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If function that we using in the apply method returns a dict or Series, the resulting output is a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda x: pd.Series({'Median': x.median(), 'Mean': x.mean()}), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda x: pd.Series({'Median': x.median(), 'Mean': x.mean()}), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **np.npv** function has 2 arguments, rate (a *float* which is the discount rate) and values (a *list* of future cashflows).\n",
    "\n",
    "For example,\n",
    "\n",
    "    np.npv(rate=0.05,values=[1,1,1,1,101])\n",
    "    \n",
    "will find the price of a 5 year bond with 1% annual coupons at a yield of 5%.\n",
    "\n",
    "Run the cell below to initialise the DataFrame we'll be working with next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bond = pd.DataFrame({'bond_name': ['Bank_2020', 'Retailer_2018', 'JGB_3Y'], 'yield': [0.0465, 0.0573, 0.00347],\n",
    "                        '2017_cashflow': [1.5, 2.5, 0.125], '2018_cashflow':[1.5, 102.5, 0.125],\n",
    "                        '2019_cashflow': [1.5, 0, 100.125], '2020_cashflow':[101.5, 0, 0]})\n",
    "df_bond.set_index('bond_name', drop=True, inplace=True)\n",
    "df_bond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Using the **.apply, lambda functions and the np.npv function**, calculate the price of each of the three bonds above.\n",
    "\n",
    "Hint: use a lambda function where the variable is a **row** from your DataFrame.\n",
    "\n",
    "This exercise is fairly difficult so take a look at the solution below if you get stuck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solutions\n",
    "%load solutions/apply_sol1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "<a id='aggregating'></a>\n",
    "# 8. GroupBy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now looked at applying functions and performing aggregations over an entire DataFrame. Often though, we are interested in aggregations among particular subsets of the data. For example, finding the turnover for each security, or median latency of different proccesses in our trading systems. Pandas allows this type of aggregation through the __df.groupby()__ method, which implements a \"split-apply-combine\" paradigm. The process is explained in the diagram below, which groups by the key and applies the sum method.\n",
    "\n",
    "<img src=\"http://nbviewer.jupyter.org/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/03.08-split-apply-combine.png\" title=\"Group-by explained\" />\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<span style=\"color:green\">Additional resources</span>\n",
    "\n",
    "http://nbviewer.jupyter.org/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.08-Aggregation-and-Grouping.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be working with volatility data, df_vols, for this section. Run the code below to import and clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vols = pd.read_csv('data/vols.csv')\n",
    "df_vols.TIMESTAMP = pd.to_datetime(df_vols.TIMESTAMP)\n",
    "df_vols = df_vols.set_index('TIMESTAMP', drop=True)\n",
    "df_vols.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some summarisation first with the .describe() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vols.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to find the mean of each column, but **per relative expiry**. We can first do a groupby on the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = df_vols.groupby('RELATIVE_EXPIRY')\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a DataFrameGroupBy object. Let's look at the attributes of this object with the Tab button or by running the __dir__ function on g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that it shares many of the same attributes and methods of the original DataFrame object. For instance, try running a few of the aggregation methods to see how they work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to perform an aggregation over a subset of columns, we can select those columns with the dict-like syntax in the usual way. Try a few of these below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g[['FUTURE', 'VOLATILITY']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to group over __ranges__ of values instead? Pandas has very useful functions __pd.cut__ and __pd.qcut__ that can bin the data into value ranges and quantile ranges respectively. Let's create 10 bins around the minimum and maximum forward price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print df_vols['FUTURE'].min(), df_vols['FUTURE'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(210, 240, 11)\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vols['FUTURE_RANGE'] = pd.cut(df_vols['FUTURE'], bins)\n",
    "df_vols.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can group by these to find the average ATM vol in each forward price bucket - is the result what you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vols.groupby('FUTURE_RANGE')['VOLATILITY'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the above calculation is actually not very informative, because we have lumped all relative expiries. We really should group over __both__ the future prices __and__ the expiries at the same time. All we need to do is to provide a list of keys/columns to groupby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_vol = df_vols.groupby(['RELATIVE_EXPIRY', 'FUTURE_RANGE'])['VOLATILITY'].mean()\n",
    "avg_vol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a Series with a MultiIndex, where relative expiry and forward price are different levels of the index. This turns out to be a much easier way of working with data than a \"3D spreadsheet\" kind of structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Whenever we get a stacked object like above, we can call the .unstack() method to turn it back into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_vol = avg_vol.unstack(level='RELATIVE_EXPIRY')  # or level=0\n",
    "df_avg_vol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Groupby objects also have a __.apply__ method, except the apply acts on each key's DataFrame. For instance, calculating the daily change of a few columns for each relative expiry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vols.groupby('RELATIVE_EXPIRY')[['FUTURE', 'VOLATILITY']].apply(lambda df: df.iloc[-1] - df.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "<a id='merging'></a>\n",
    "# 9. Merge/Join\n",
    "\n",
    "Sometimes we will want to complement one data set with information from another data set. For example, joining a DataFrame of trades (price, size, time) with a DataFrame of instrument properties (underlying, expiry date, strike price). Pandas' main method for joining two DataFrames is __pd.merge__:\n",
    "\n",
    "    pd.merge(df_left, df_right, on=..., how=...)\n",
    "    \n",
    "The 'on' argument determines which column(s) to join on. If left empty, the columns that df_left and df_right share will be used as join keys. If the columns to join on have different names between df_left and df_right, we can use the 'left_on' and 'right_on' arguments instead. To join on the index instead of a column, we use left_index=True and/or right_index=True. Alternatively, df_left.join(df_right) performs a join on the indexes.\n",
    "\n",
    "The ‘how’ argument determines the style of join to use. Options for this argument are ‘inner’, 'outer', 'left', and 'right'. An inner join contains the intersection of the two sets of inputs. An outer join returns a join over the union of the input columns, and fills in all missing values with NaNs. The left and right joins return joins over the left and right indices respectively. Note that a right join is identical to a left join with the left/right labels swapped - so we usually just use left joins.\n",
    "\n",
    "<img src=\"http://www.w3schools.com/sql/img_innerjoin.gif\" title=\"Inner join\" />\n",
    "<img src=\"http://www.w3schools.com/sql/img_leftjoin.gif\" title=\"Left join\" />\n",
    "<img src=\"http://www.w3schools.com/sql/img_rightjoin.gif\" title=\"Right join\" />\n",
    "<img src=\"http://www.w3schools.com/sql/img_fulljoin.gif\" title=\"Outer join\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<span style=\"color:green\">YouTube video</span>\n",
    "\n",
    "Watch the following video until the 1 hour 13 minute mark to get a better idea of these methods.\n",
    "\n",
    "https://www.youtube.com/watch?v=dye7rDktJ2E&start=3180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key methods covered:**\n",
    "\n",
    "    pd.concat - combines two objects into a single DataFrame\n",
    "    pd.merge - merges existing DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<span style=\"color:green\">Additional resources</span>\n",
    "\n",
    "http://nbviewer.jupyter.org/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.07-Merge-and-Join.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load up the following data of prices and turnovers (assume a multiplier of 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_turnovers = pd.DataFrame(columns=['Underlying', 'Month', 'Turnover'],\n",
    "    data={'Underlying': ['HSI']*3 + ['NK225']*3 + ['HHI']*3,\n",
    "          'Month': ['Jan', 'Feb', 'Mar']*3,\n",
    "          'Turnover': [1000, 1100,   900,\n",
    "                        300,  350,   400,\n",
    "                       6000, 7000, np.nan]})\n",
    "df_turnovers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices = pd.DataFrame(columns=['Underlying', 'Month', 'Price'],\n",
    "    data={'Underlying': ['HSI']*3 + ['HHI']*3 + ['NK225']*3,\n",
    "          'Month': ['Jan', 'Feb', 'Mar']*3,\n",
    "          'Price': [28000, 29000, 30000,\n",
    "                    11000, 12000, 115000,\n",
    "                    22000, 21000, 20000]})\n",
    "df_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the notional turnover (price times size) in local currency by joining on the appropriate key(s) with __pd.merge__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solutions\n",
    "%load solutions/merge_sol1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load the following currency data, and join them together to get the forex rates for each underlying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_currency = pd.DataFrame({'Underlying': ['NK225', 'HSI', 'HHI'], 'Currency': ['JPY', 'HKD', 'HKD']})\n",
    "df_currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forex = pd.DataFrame({'Currency': ['HKD', 'JPY', 'KRW'], 'Rate': [6, 80, 850]})\n",
    "df_forex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solutions\n",
    "%load solutions/merge_sol2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, join currency data onto the notional turnover data and convert the notional turnover to AUD (in millions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solutions\n",
    "%load solutions/merge_sol3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise set 3 (unavailable externally)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise set we'll use our HSI options data. For now, just run the following cells to get our trade data from OneTick - we'll spend time learning how to use OneTick later. You'll need to install the following package first:\n",
    ">pip install optiver.etl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from etl.onetick import otq, query\n",
    "import datetime as dt\n",
    "\n",
    "start = dt.datetime(2018, 3, 13, 0, 0)\n",
    "end = dt.datetime(2018, 3, 13, 23, 59)\n",
    "\n",
    "# Trade data\n",
    "q = query.tick_query('Trade_Tick_Analysis', 'ATLAS_IN',\n",
    "                     start, end, 'Australia/Sydney',\n",
    "                     symbol_regex='ATLAS_IN::opa_in_hsi_tko_001.XHKF',\n",
    "                     columns=['EEID_TIMESTAMP', 'FEEDCODE', 'TRADE_PRICE', 'TRADE_VOLUME', 'THEO_PRICE', 'DELTA'])\n",
    "\n",
    "df_trd = otq.query(q)\n",
    "df_trd = df_trd.drop(columns=['Time', 'SYMBOL_NAME'])\n",
    "df_trd['EEID_TIMESTAMP'] = pd.to_datetime(df_trd['EEID_TIMESTAMP'])\n",
    "df_trd = df_trd.set_index('EEID_TIMESTAMP')\n",
    "df_trd = df_trd[df_trd['FEEDCODE'].str.startswith('HSI')]\n",
    "\n",
    "# Instrument data\n",
    "q = query.tick_query('Instrument', 'XHKF',\n",
    "                     start, end, 'Australia/Sydney',\n",
    "                     symbol_regex='XHKF::HSI',\n",
    "                     columns=['FEEDCODE', 'KIND', 'STRIKE_PRICE', 'EXPIRY_DATE'])\n",
    "\n",
    "df_ins = otq.query(q)\n",
    "df_ins = df_ins.drop(columns=['Time', 'SYMBOL_NAME'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Add a new column EDGE to df_trd that contains the total edge of that trade in AUD.\n",
    "2. Merge the instrument data into the trade data.\n",
    "3. Calculate the total edge and trade volumes per delta bucket (delta 0-10, 10-20, 20-30, etc.), expiry date, and instrument kind.\n",
    "4. Unstack that dataframe so that it's easier to view.\n",
    "5. Sort the dataframe in descending order of edge.\n",
    "6. What was the total edge for the day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DELTA',\n",
       " 'FEEDCODE',\n",
       " 'THEO_PRICE',\n",
       " 'THEO_PRICE_ADJUST',\n",
       " 'TRADE_PRICE',\n",
       " 'TRADE_VOLUME']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_trd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trd['EDGE'] = (df_trd['THEO_PRICE'] - df_trd['TRADE_PRICE']).abs() * df_trd['TRADE_VOLUME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2086\n",
      "2071\n"
     ]
    }
   ],
   "source": [
    "print len(df_ins)\n",
    "df_ins = df_ins.drop_duplicates('FEEDCODE')\n",
    "print len(df_ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DELTA</th>\n",
       "      <th>FEEDCODE</th>\n",
       "      <th>THEO_PRICE</th>\n",
       "      <th>THEO_PRICE_ADJUST</th>\n",
       "      <th>TRADE_PRICE</th>\n",
       "      <th>TRADE_VOLUME</th>\n",
       "      <th>EDGE</th>\n",
       "      <th>EXPIRY_DATE</th>\n",
       "      <th>KIND</th>\n",
       "      <th>STRIKE_PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.162750</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.488250</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.743250</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.162750</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.162750</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.651000</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.627500</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.139250</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.417750</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.139250</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.139250</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.627500</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.813750</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.651000</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.953000</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.325500</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.162750</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.162750</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.255000</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.488250</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.651000</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.813750</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.813750</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.651000</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.162750</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.651000</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.417750</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.162750</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.325500</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31550.162750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.488250</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89519</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31585.074308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31585.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.074308</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89520</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31585.074308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31584.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.074308</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89521</th>\n",
       "      <td>0.426614</td>\n",
       "      <td>HSI31800C8</td>\n",
       "      <td>361.391912</td>\n",
       "      <td>0.721095</td>\n",
       "      <td>363.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.824265</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Call</td>\n",
       "      <td>31800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89522</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31584.569679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31584.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569679</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89523</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31584.569679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31583.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.569679</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89524</th>\n",
       "      <td>0.431041</td>\n",
       "      <td>HSI32000D8</td>\n",
       "      <td>631.659705</td>\n",
       "      <td>0.696076</td>\n",
       "      <td>634.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.340295</td>\n",
       "      <td>2018-04-26 14:00:00</td>\n",
       "      <td>Call</td>\n",
       "      <td>32000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89525</th>\n",
       "      <td>-0.132534</td>\n",
       "      <td>HSI30200O8</td>\n",
       "      <td>104.131358</td>\n",
       "      <td>0.252247</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.262716</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Put</td>\n",
       "      <td>30200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89526</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31584.369395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31583.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.369395</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89527</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31583.769336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31585.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.461328</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89528</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31583.169103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31584.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.830897</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89529</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31583.268807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31584.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.731193</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89530</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31583.268807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31585.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.731193</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89531</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31583.468747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31585.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.531253</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89532</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31583.468629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31582.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.468629</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89533</th>\n",
       "      <td>0.517498</td>\n",
       "      <td>HSI31600D8</td>\n",
       "      <td>827.503878</td>\n",
       "      <td>-0.024860</td>\n",
       "      <td>831.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.496122</td>\n",
       "      <td>2018-04-26 14:00:00</td>\n",
       "      <td>Call</td>\n",
       "      <td>31600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89534</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31584.488625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31586.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.534125</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89535</th>\n",
       "      <td>-0.013244</td>\n",
       "      <td>HSI28000O8</td>\n",
       "      <td>13.210459</td>\n",
       "      <td>-0.057484</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.789541</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Put</td>\n",
       "      <td>28000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89536</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31584.488625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31582.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.488625</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89537</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31584.088595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31585.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.911405</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89538</th>\n",
       "      <td>0.475272</td>\n",
       "      <td>HSI31800D8</td>\n",
       "      <td>725.299570</td>\n",
       "      <td>-0.125074</td>\n",
       "      <td>723.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.299570</td>\n",
       "      <td>2018-04-26 14:00:00</td>\n",
       "      <td>Call</td>\n",
       "      <td>31800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89539</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31584.688589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31586.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.311411</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89540</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31584.787902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31586.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.212098</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89541</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31584.100446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31584.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.200891</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89542</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31586.300897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31586.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.300897</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89543</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31586.101046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31586.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.101046</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89544</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31586.101343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31588.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.898657</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89545</th>\n",
       "      <td>0.128714</td>\n",
       "      <td>HSI34800F8</td>\n",
       "      <td>229.511321</td>\n",
       "      <td>0.228494</td>\n",
       "      <td>225.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.090571</td>\n",
       "      <td>2018-06-27 14:00:00</td>\n",
       "      <td>Call</td>\n",
       "      <td>34800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89546</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31587.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31590.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89547</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31588.698072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31586.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.698072</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89548</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>HSIH8</td>\n",
       "      <td>31587.597693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31586.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.597693</td>\n",
       "      <td>2018-03-27 13:00:00</td>\n",
       "      <td>Future</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89549 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DELTA    FEEDCODE    THEO_PRICE  THEO_PRICE_ADJUST  TRADE_PRICE  \\\n",
       "0      1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "1      1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "2      1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "3      1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "4      1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "5      1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "6      1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "7      1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "8      1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "9      1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "10     1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "11     1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "12     1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "13     1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "14     1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "15     1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "16     1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "17     1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "18     1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "19     1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "20     1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "21     1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "22     1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "23     1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "24     1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "25     1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "26     1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "27     1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "28     1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "29     1.000000       HSIH8  31550.162750           0.000000      31550.0   \n",
       "...         ...         ...           ...                ...          ...   \n",
       "89519  1.000000       HSIH8  31585.074308           0.000000      31585.0   \n",
       "89520  1.000000       HSIH8  31585.074308           0.000000      31584.0   \n",
       "89521  0.426614  HSI31800C8    361.391912           0.721095        363.0   \n",
       "89522  1.000000       HSIH8  31584.569679           0.000000      31584.0   \n",
       "89523  1.000000       HSIH8  31584.569679           0.000000      31583.0   \n",
       "89524  0.431041  HSI32000D8    631.659705           0.696076        634.0   \n",
       "89525 -0.132534  HSI30200O8    104.131358           0.252247        103.0   \n",
       "89526  1.000000       HSIH8  31584.369395           0.000000      31583.0   \n",
       "89527  1.000000       HSIH8  31583.769336           0.000000      31585.0   \n",
       "89528  1.000000       HSIH8  31583.169103           0.000000      31584.0   \n",
       "89529  1.000000       HSIH8  31583.268807           0.000000      31584.0   \n",
       "89530  1.000000       HSIH8  31583.268807           0.000000      31585.0   \n",
       "89531  1.000000       HSIH8  31583.468747           0.000000      31585.0   \n",
       "89532  1.000000       HSIH8  31583.468629           0.000000      31582.0   \n",
       "89533  0.517498  HSI31600D8    827.503878          -0.024860        831.0   \n",
       "89534  1.000000       HSIH8  31584.488625           0.000000      31586.0   \n",
       "89535 -0.013244  HSI28000O8     13.210459          -0.057484         14.0   \n",
       "89536  1.000000       HSIH8  31584.488625           0.000000      31582.0   \n",
       "89537  1.000000       HSIH8  31584.088595           0.000000      31585.0   \n",
       "89538  0.475272  HSI31800D8    725.299570          -0.125074        723.0   \n",
       "89539  1.000000       HSIH8  31584.688589           0.000000      31586.0   \n",
       "89540  1.000000       HSIH8  31584.787902           0.000000      31586.0   \n",
       "89541  1.000000       HSIH8  31584.100446           0.000000      31584.0   \n",
       "89542  1.000000       HSIH8  31586.300897           0.000000      31586.0   \n",
       "89543  1.000000       HSIH8  31586.101046           0.000000      31586.0   \n",
       "89544  1.000000       HSIH8  31586.101343           0.000000      31588.0   \n",
       "89545  0.128714  HSI34800F8    229.511321           0.228494        225.0   \n",
       "89546  1.000000       HSIH8  31587.700000           0.000000      31590.0   \n",
       "89547  1.000000       HSIH8  31588.698072           0.000000      31586.0   \n",
       "89548  1.000000       HSIH8  31587.597693           0.000000      31586.0   \n",
       "\n",
       "       TRADE_VOLUME       EDGE         EXPIRY_DATE    KIND  STRIKE_PRICE  \n",
       "0               1.0   0.162750 2018-03-27 13:00:00  Future           NaN  \n",
       "1               3.0   0.488250 2018-03-27 13:00:00  Future           NaN  \n",
       "2              23.0   3.743250 2018-03-27 13:00:00  Future           NaN  \n",
       "3               1.0   0.162750 2018-03-27 13:00:00  Future           NaN  \n",
       "4               1.0   0.162750 2018-03-27 13:00:00  Future           NaN  \n",
       "5               4.0   0.651000 2018-03-27 13:00:00  Future           NaN  \n",
       "6              10.0   1.627500 2018-03-27 13:00:00  Future           NaN  \n",
       "7               7.0   1.139250 2018-03-27 13:00:00  Future           NaN  \n",
       "8              21.0   3.417750 2018-03-27 13:00:00  Future           NaN  \n",
       "9               7.0   1.139250 2018-03-27 13:00:00  Future           NaN  \n",
       "10              7.0   1.139250 2018-03-27 13:00:00  Future           NaN  \n",
       "11             10.0   1.627500 2018-03-27 13:00:00  Future           NaN  \n",
       "12              5.0   0.813750 2018-03-27 13:00:00  Future           NaN  \n",
       "13              4.0   0.651000 2018-03-27 13:00:00  Future           NaN  \n",
       "14             12.0   1.953000 2018-03-27 13:00:00  Future           NaN  \n",
       "15              2.0   0.325500 2018-03-27 13:00:00  Future           NaN  \n",
       "16              1.0   0.162750 2018-03-27 13:00:00  Future           NaN  \n",
       "17              1.0   0.162750 2018-03-27 13:00:00  Future           NaN  \n",
       "18             20.0   3.255000 2018-03-27 13:00:00  Future           NaN  \n",
       "19              3.0   0.488250 2018-03-27 13:00:00  Future           NaN  \n",
       "20              4.0   0.651000 2018-03-27 13:00:00  Future           NaN  \n",
       "21              5.0   0.813750 2018-03-27 13:00:00  Future           NaN  \n",
       "22              5.0   0.813750 2018-03-27 13:00:00  Future           NaN  \n",
       "23              4.0   0.651000 2018-03-27 13:00:00  Future           NaN  \n",
       "24              1.0   0.162750 2018-03-27 13:00:00  Future           NaN  \n",
       "25              4.0   0.651000 2018-03-27 13:00:00  Future           NaN  \n",
       "26             21.0   3.417750 2018-03-27 13:00:00  Future           NaN  \n",
       "27              1.0   0.162750 2018-03-27 13:00:00  Future           NaN  \n",
       "28              2.0   0.325500 2018-03-27 13:00:00  Future           NaN  \n",
       "29              3.0   0.488250 2018-03-27 13:00:00  Future           NaN  \n",
       "...             ...        ...                 ...     ...           ...  \n",
       "89519           1.0   0.074308 2018-03-27 13:00:00  Future           NaN  \n",
       "89520           1.0   1.074308 2018-03-27 13:00:00  Future           NaN  \n",
       "89521           3.0   4.824265 2018-03-27 13:00:00    Call       31800.0  \n",
       "89522           1.0   0.569679 2018-03-27 13:00:00  Future           NaN  \n",
       "89523           1.0   1.569679 2018-03-27 13:00:00  Future           NaN  \n",
       "89524           1.0   2.340295 2018-04-26 14:00:00    Call       32000.0  \n",
       "89525           2.0   2.262716 2018-03-27 13:00:00     Put       30200.0  \n",
       "89526           1.0   1.369395 2018-03-27 13:00:00  Future           NaN  \n",
       "89527           2.0   2.461328 2018-03-27 13:00:00  Future           NaN  \n",
       "89528           1.0   0.830897 2018-03-27 13:00:00  Future           NaN  \n",
       "89529           1.0   0.731193 2018-03-27 13:00:00  Future           NaN  \n",
       "89530           1.0   1.731193 2018-03-27 13:00:00  Future           NaN  \n",
       "89531           1.0   1.531253 2018-03-27 13:00:00  Future           NaN  \n",
       "89532           1.0   1.468629 2018-03-27 13:00:00  Future           NaN  \n",
       "89533           1.0   3.496122 2018-04-26 14:00:00    Call       31600.0  \n",
       "89534           3.0   4.534125 2018-03-27 13:00:00  Future           NaN  \n",
       "89535           1.0   0.789541 2018-03-27 13:00:00     Put       28000.0  \n",
       "89536           1.0   2.488625 2018-03-27 13:00:00  Future           NaN  \n",
       "89537           1.0   0.911405 2018-03-27 13:00:00  Future           NaN  \n",
       "89538           1.0   2.299570 2018-04-26 14:00:00    Call       31800.0  \n",
       "89539           1.0   1.311411 2018-03-27 13:00:00  Future           NaN  \n",
       "89540           1.0   1.212098 2018-03-27 13:00:00  Future           NaN  \n",
       "89541           2.0   0.200891 2018-03-27 13:00:00  Future           NaN  \n",
       "89542           1.0   0.300897 2018-03-27 13:00:00  Future           NaN  \n",
       "89543           1.0   0.101046 2018-03-27 13:00:00  Future           NaN  \n",
       "89544           1.0   1.898657 2018-03-27 13:00:00  Future           NaN  \n",
       "89545           8.0  36.090571 2018-06-27 14:00:00    Call       34800.0  \n",
       "89546           1.0   2.300000 2018-03-27 13:00:00  Future           NaN  \n",
       "89547           1.0   2.698072 2018-03-27 13:00:00  Future           NaN  \n",
       "89548           1.0   1.597693 2018-03-27 13:00:00  Future           NaN  \n",
       "\n",
       "[89549 rows x 10 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_trd, df_ins, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot sort by column EDGE in a multi-index you need to explicitly provide all the levels",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-8ccb4c1067a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# 5. Sort by edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mgroups_unstacked\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'EDGE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36msort_values\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position)\u001b[0m\n\u001b[0;32m   3624\u001b[0m         ...                   columns=['A', 'B', 'C', 'D'])\n\u001b[0;32m   3625\u001b[0m         \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3626\u001b[1;33m            \u001b[0mA\u001b[0m  \u001b[0mB\u001b[0m   \u001b[0mC\u001b[0m   \u001b[0mD\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3627\u001b[0m         \u001b[1;36m0\u001b[0m  \u001b[1;36m0\u001b[0m  \u001b[1;36m1\u001b[0m   \u001b[1;36m2\u001b[0m   \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3628\u001b[0m         \u001b[1;36m1\u001b[0m  \u001b[1;36m4\u001b[0m  \u001b[1;36m5\u001b[0m   \u001b[1;36m6\u001b[0m   \u001b[1;36m7\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot sort by column EDGE in a multi-index you need to explicitly provide all the levels"
     ]
    }
   ],
   "source": [
    "# 1. Calculate edge as |theo-trade|\n",
    "df_trd['EDGE'] = (df_trd['THEO_PRICE'] - df_trd['TRADE_PRICE']).abs() * df_trd['TRADE_VOLUME']\n",
    "\n",
    "# 2. Join on instrument data\n",
    "df_ins = df_ins.drop_duplicates('FEEDCODE')  # drop any duplicate instrument ticks\n",
    "df = pd.merge(df_trd, df_ins, 'left')  # left join so we don't drop trades\n",
    "\n",
    "# 3. Make delta buckets, sum over edge and volume\n",
    "delta_range = np.linspace(0, 1, 11)\n",
    "df['DELTA_BUCKET'] = pd.cut(df['DELTA'].abs(), delta_range)\n",
    "\n",
    "groups = df.groupby(['DELTA_BUCKET', 'EXPIRY_DATE', 'KIND'])\n",
    "groups = groups[['TRADE_VOLUME', 'EDGE']]  # keep these two columns only\n",
    "groups_sum = groups.sum().sort_values('EDGE', ascending=False)\n",
    "\n",
    "# 4. Unstack\n",
    "groups_unstacked = groups_sum.unstack('KIND')  # pull out from index to columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_unstacked"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
